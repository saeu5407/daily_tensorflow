{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dcgan.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPU1HoWjB/EwMHHgD52QWOE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saeu5407/daily_tensorflow/blob/main/dcgan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUdxpFMMN5W5"
      },
      "source": [
        "# DCGAN\n",
        "\n",
        "이번에는 텐서플로우 튜토리얼 중 심층 합성곱 생성적 적대 신경망(DCGAN)에 대해 실습하겠습니다.\n",
        "\n",
        "### DCGAN이란\n",
        "\n",
        "요즘 자주 쓰이는 아이디어로, 두 개의 모델이 적대적인 과정을 통해 동시에 훈련을 하는 기법입니다.\n",
        "각 모델을 생성자, 감별자라고 합니다.\n",
        "\n",
        "각 모델은 다음과 같이 학습되게 됩니다.\n",
        "생성자 : 진짜처럼 보이는 이미지를 생성.\n",
        "감별자 : 생성자가 생성한 이미지가 가짜인지 구별.\n",
        "\n",
        "훈련과정 동안 생성자는 점차 실제같은 이미지를 더 잘 생성하게 되고, 감별자는 점차 진짜와 가짜를 더 잘 구별하게됩니다. 이 과정은 감별자가 가짜 이미지에서 진짜 이미지를 더이상 구별하지 못하게 될때, 평형상태에 도달하게 됩니다.\n",
        "\n",
        "텐서플로우 튜토리얼 원본 링크 [텐서플로우 DCGAN](https://https://www.tensorflow.org/tutorials/generative/dcgan?hl=ko)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "CSEGz8tdNoeY",
        "outputId": "93f643ea-7772-408e-ad11-343b818db293"
      },
      "source": [
        "!pip install -q tensorflow-gpu==2.0.0-rc1\n",
        "import tensorflow as tf\n",
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 380.5 MB 9.1 kB/s \n",
            "\u001b[K     |████████████████████████████████| 4.3 MB 41.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 501 kB 59.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 50 kB 7.2 MB/s \n",
            "\u001b[?25h"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.0.0-rc1'"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hp8S4y_xNyMT"
      },
      "source": [
        "# GIF를 만들기위해 설치합니다.\n",
        "!pip install -q imageio"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUQxwRAuNyN0"
      },
      "source": [
        "import glob\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "from tensorflow.keras import layers\n",
        "import time\n",
        "\n",
        "from IPython import display"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijMACjZXPtFb"
      },
      "source": [
        "### 데이터셋 로드 및 준비"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWpp7Kj3NyTx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3a287d4-f9aa-4d69-c994-e2f225a11f23"
      },
      "source": [
        "(train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n",
        "train_images = (train_images - 127.5) / 127.5 # 이미지를 [-1, 1]로 정규화합니다.\n",
        "\n",
        "BUFFER_SIZE = 60000\n",
        "BATCH_SIZE = 256\n",
        "\n",
        "# 데이터 배치를 만들고 섞습니다.\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4IBbJcsxP2un"
      },
      "source": [
        "### 모델링"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yxVDW8hP_Zj"
      },
      "source": [
        "#### 감별자(Discriminator)\n",
        "\n",
        "합성곱 신경망(Convolutional Neural Network, CNN) 기반의 이미지 분류기입니다.\n",
        "\n",
        "감별자를 사용하여 생성된 이미지가 진짜인지 가짜인지 판별합니다. 모델은 진짜 이미지에는 양수의 값 (positive values)을, 가짜 이미지에는 음수의 값 (negative values)을 출력하도록 훈련되어집니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glNGKmUvNyWf"
      },
      "source": [
        "# Discriminator\n",
        "\"\"\"\n",
        "일반적인 CNN 모델\n",
        "\"\"\"\n",
        "def make_discriminator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',\n",
        "                                     input_shape=[28, 28, 1]))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(1))\n",
        "\n",
        "    return model\n",
        "\n",
        "discriminator = make_discriminator_model()\n",
        "decision = discriminator(generated_image)\n",
        "print (decision)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24-ONiIw0X9e"
      },
      "source": [
        "감별자의 손실함수는\n",
        "진짜 이미지에 대한 감별자의 예측과 1로 이루어진 행렬 두 가지를 비교하고,<br> 가짜 (생성된)이미지에 대한 감별자의 예측과 0으로 이루어진 행렬을 비교합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7sS1Om30PjR"
      },
      "source": [
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "# 감별자 손실함수\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NhPivrKP_Xf"
      },
      "source": [
        "#### 생성자\n",
        "생성자는 시드값으로부터 이미지를 생성하기 위해, tf.keras.layers.Conv2DTranspose(업샘플링) 층을 이용합니다. 처음 Dense층은 이 시드값을 인풋으로 받습니다. 그 다음 원하는 사이즈 28x28x1의 이미지가 나오도록 업샘플링을 여러번 합니다. tanh를 사용하는 마지막 층을 제외한 나머지 각 층마다 활성함수로 tf.keras.layers.LeakyReLU을 사용하고 있음을 주목합시다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qDGfcqmNyc0"
      },
      "source": [
        "def make_generator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,)))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Reshape((7, 7, 256)))\n",
        "    assert model.output_shape == (None, 7, 7, 256) # 주목: 배치사이즈로 None이 주어집니다.\n",
        "\n",
        "    # Conv2DTranspose 적용 부분, 최종적으로 28x28의 크기로 스케일을 올린다.\n",
        "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 7, 7, 128)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 14, 14, 64)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
        "    assert model.output_shape == (None, 28, 28, 1)\n",
        "\n",
        "    return model\n",
        "\n",
        "generator = make_generator_model()\n",
        "\n",
        "noise = tf.random.normal([1, 100])\n",
        "generated_image = generator(noise, training=False)\n",
        "\n",
        "plt.imshow(generated_image[0, :, :, 0], cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aY1G8TgB0x3W"
      },
      "source": [
        "생성자의 손실함수는 감별자에 대한 수치화 지표입니다. 생성된 이미지에 대한 감별자의 결정과 1로 이루어진 행렬을 비교합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivaxZmg3NyfV"
      },
      "source": [
        "# 생성자 손실함수\n",
        "def generator_loss(fake_output):\n",
        "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DunQzPt1F6i"
      },
      "source": [
        "# 두 모델이 다르기 때문에 옵티마이저를 따로 구성합니다.\n",
        "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDKN6bQ61R0V"
      },
      "source": [
        "#### 모델 구현부"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdbxydIF1OYb"
      },
      "source": [
        "# 체크포인트 저장\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "                                 discriminator_optimizer=discriminator_optimizer,\n",
        "                                 generator=generator,\n",
        "                                 discriminator=discriminator)\n",
        "\n",
        "# 시드 고정 및 각 파라미터 고정\n",
        "EPOCHS = 50\n",
        "noise_dim = 100\n",
        "num_examples_to_generate = 16\n",
        "\n",
        "# 이 시드를 시간이 지나도 재활용하겠습니다. \n",
        "# (GIF 애니메이션에서 진전 내용을 시각화하는데 쉽기 때문입니다.) \n",
        "seed = tf.random.normal([num_examples_to_generate, noise_dim])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dcb2vJO1knh"
      },
      "source": [
        "# 모델 훈련 함수(메인 함수에 들어갈 예정)\n",
        "# `tf.function`이 어떻게 사용되는지 주목해 주세요.\n",
        "# 이 데코레이터는 함수를 \"컴파일\"합니다.\n",
        "\"\"\"\n",
        "@tf.function은 tf1.x 스타일로 함수 내 로직이 동작하게끔 해 주는 방법입니다.\n",
        "현재 tf2.x이상 버젼에서는 tf.Session등 추가적인 방법 없이 간편하게 돌아가게끔 구성이 되어 있지만, \n",
        "그래프의 생성과 실행이 분리되어 있는 tf1.x가 속도에 이점이 있을 수 있습니다.\n",
        "다만 해당 annotation을 붙이면 값을 바로 계산해볼수 없어서 모든 로직에 대한 프로그래밍이 끝난 뒤에 붙이는 것이 좋다고 합니다.\n",
        "\"\"\"\n",
        "@tf.function\n",
        "def train_step(images):\n",
        "    noise = tf.random.normal([BATCH_SIZE, noise_dim]) # 랜덤함수로 노이즈 생성\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape: # with as를 이렇게 ,를 활용하여 쓸 수 있음.\n",
        "      # tf.GradientTape()는 자동 미분을 도와주는 함수로, 모든 연산을 테이프(tape)에 기록 후 기록 된 연산의 그래디언트를 계산합니다.\n",
        "      generated_images = generator(noise, training=True) # 생성자\n",
        "\n",
        "      real_output = discriminator(images, training=True) # 이미지에 대한 판별\n",
        "      fake_output = discriminator(generated_images, training=True) # 생성자가 만든 이미지에 대한 판별\n",
        "\n",
        "      # 각 Loss 계산\n",
        "      gen_loss = generator_loss(fake_output) \n",
        "      disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "    # 그래디언트 계산\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    # 오차역전파 업데이트\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rne62u691ksH"
      },
      "source": [
        "# 이미지 생성 함수\n",
        "def generate_and_save_images(model, epoch, test_input):\n",
        "  # `training`이 False로 맞춰진 것을 주목하세요.\n",
        "  # 이렇게 하면 (배치정규화를 포함하여) 모든 층들이 추론 모드로 실행됩니다. \n",
        "  predictions = model(test_input, training=False)\n",
        "\n",
        "  fig = plt.figure(figsize=(4,4))\n",
        "\n",
        "  for i in range(predictions.shape[0]):\n",
        "      plt.subplot(4, 4, i+1)\n",
        "      plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
        "      plt.axis('off')\n",
        "\n",
        "  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1n1b5MZA1kp6"
      },
      "source": [
        "# 메인 훈련 함수\n",
        "def train(dataset, epochs):\n",
        "  for epoch in range(epochs):\n",
        "    start = time.time()\n",
        "\n",
        "    # 위의 훈련 함수를 통해 훈련 수행\n",
        "    for image_batch in dataset:\n",
        "      train_step(image_batch)\n",
        "\n",
        "    # GIF를 위한 이미지를 바로 생성합니다.\n",
        "    display.clear_output(wait=True)\n",
        "    generate_and_save_images(generator,\n",
        "                             epoch + 1,\n",
        "                             seed)\n",
        "\n",
        "    # 15 에포크가 지날 때마다 모델을 저장합니다.\n",
        "    if (epoch + 1) % 15 == 0:\n",
        "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "    # print (' 에포크 {} 에서 걸린 시간은 {} 초 입니다'.format(epoch +1, time.time()-start))\n",
        "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
        "\n",
        "  # 마지막 에포크가 끝난 후 생성합니다.\n",
        "  display.clear_output(wait=True)\n",
        "  generate_and_save_images(generator,\n",
        "                           epochs,\n",
        "                           seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HF0Dfq_1wTR"
      },
      "source": [
        "#### 모델 훈련"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-7g0Q2E1kug"
      },
      "source": [
        "%%time\n",
        "train(train_dataset, EPOCHS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbnPfXFM1kwv"
      },
      "source": [
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnkxEjMg1kzH"
      },
      "source": [
        "# 에포크 숫자를 사용하여 하나의 이미지를 보여줍니다.\n",
        "def display_image(epoch_no):\n",
        "  return PIL.Image.open('image_at_epoch_{:04d}.png'.format(epoch_no))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kShwsYNp1k1g"
      },
      "source": [
        "display_image(EPOCHS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-QsiG5l-3tK"
      },
      "source": [
        "#### 추가 : GIF 생성 및 저장"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTcRFDNi1k3_"
      },
      "source": [
        "anim_file = 'dcgan.gif'\n",
        "\n",
        "with imageio.get_writer(anim_file, mode='I') as writer:\n",
        "  filenames = glob.glob('image*.png')\n",
        "  filenames = sorted(filenames)\n",
        "  last = -1\n",
        "  for i,filename in enumerate(filenames):\n",
        "    frame = 2*(i**0.5)\n",
        "    if round(frame) > round(last):\n",
        "      last = frame\n",
        "    else:\n",
        "      continue\n",
        "    image = imageio.imread(filename)\n",
        "    writer.append_data(image)\n",
        "  image = imageio.imread(filename)\n",
        "  writer.append_data(image)\n",
        "\n",
        "import IPython\n",
        "if IPython.version_info > (6,2,0,''):\n",
        "  display.Image(filename=anim_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPrFcIh718eP"
      },
      "source": [
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "  pass\n",
        "else:\n",
        "  files.download(anim_file)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}