{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "seq2seq.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMc3dGQwiroOF9a268mjaEx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saeu5407/daily_tensorflow/blob/main/seq2seq.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKyUjiImvwrg"
      },
      "source": [
        "# Seq2seq\n",
        "\n",
        "seq2seq를 활용해 기계번역을 진행해보도록 하겠습니다.\n",
        "\n",
        "[원본 텐서플로우 튜토리얼 링크](https://www.tensorflow.org/text/tutorials/nmt_with_attention?hl=ko)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6soYOUn8vl4z"
      },
      "source": [
        "pip install tensorflow_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnKo_7nEv-dA"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import typing\n",
        "from typing import Any, Tuple\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "\n",
        "import tensorflow_text as tf_text\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LE5ANTljv-fZ"
      },
      "source": [
        "# 모양을 확인하는 데 사용하기 위해 정의해 둔 저수준 API 관련 옵션\n",
        "use_builtins = True"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtZgB1N8wVJb"
      },
      "source": [
        "하단 코드는 모양 검사를 위한 코드입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkcM6fOjdamQ"
      },
      "source": [
        "class ShapeChecker():\n",
        "  def __init__(self):\n",
        "    # Keep a cache of every axis-name seen\n",
        "    self.shapes = {}\n",
        "\n",
        "  def __call__(self, tensor, names, broadcast=False):\n",
        "    if not tf.executing_eagerly():\n",
        "      return\n",
        "\n",
        "    if isinstance(names, str):\n",
        "      names = (names,)\n",
        "\n",
        "    shape = tf.shape(tensor)\n",
        "    rank = tf.rank(tensor)\n",
        "\n",
        "    if rank != len(names):\n",
        "      raise ValueError(f'Rank mismatch:\\n'\n",
        "                       f'    found {rank}: {shape.numpy()}\\n'\n",
        "                       f'    expected {len(names)}: {names}\\n')\n",
        "\n",
        "    for i, name in enumerate(names):\n",
        "      if isinstance(name, int):\n",
        "        old_dim = name\n",
        "      else:\n",
        "        old_dim = self.shapes.get(name, None)\n",
        "      new_dim = shape[i]\n",
        "\n",
        "      if (broadcast and new_dim == 1):\n",
        "        continue\n",
        "\n",
        "      if old_dim is None:\n",
        "        # If the axis name is new, add its length to the cache.\n",
        "        self.shapes[name] = new_dim\n",
        "        continue\n",
        "\n",
        "      if new_dim != old_dim:\n",
        "        raise ValueError(f\"Shape mismatch for dimension: '{name}'\\n\"\n",
        "                         f\"    found: {new_dim}\\n\"\n",
        "                         f\"    expected: {old_dim}\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xu1amXmwwmLM"
      },
      "source": [
        "## 데이터셋 로드 및 준비\n",
        "\n",
        "텐서플로우 튜토리얼을 따라 영어-스페인어 데이터 세트를 사용해 데이터셋을 로드합니다.\n",
        "해당 데이터세트는 다음과 같이 한 쌍으로 구성되어 있습니다.\n",
        "\n",
        "```\n",
        "May I borrow this book? ¿Puedo tomar prestado este libro?\n",
        "```\n",
        "\n",
        "다운받은 데이터에 대해 다음과 같은 작업을 진행합니다.\n",
        "1. 각 문장에 토큰 시작과 끝을 추가\n",
        "2. 특수 문자 제거\n",
        "3. 단어 -> id, id -> 단어 등 사전 매핑\n",
        "4. 각 문장을 최대 길이로 채움"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aC6e3Fl1zr-p"
      },
      "source": [
        "### 데이터 다운로드 및 로드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLvSlif3v-iX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce576af6-7cf6-4ba4-92c5-b70cb63384ff"
      },
      "source": [
        "# 데이터 다운로드\n",
        "import pathlib\n",
        "\n",
        "path_to_zip = tf.keras.utils.get_file(\n",
        "    'spa-eng.zip', origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip',\n",
        "    extract=True)\n",
        "\n",
        "path_to_file = pathlib.Path(path_to_zip).parent/'spa-eng/spa.txt'"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n",
            "2646016/2638744 [==============================] - 0s 0us/step\n",
            "2654208/2638744 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7FshGHWv-kf"
      },
      "source": [
        "# 데이터 로드 함수 정의\n",
        "def load_data(path):\n",
        "  text = path.read_text(encoding='utf-8')\n",
        "\n",
        "  lines = text.splitlines() # 여러 라인으로 구분된 문자열을 한 라인씩 분리하여 리스트 반환\n",
        "  pairs = [line.split('\\t') for line in lines] # 그 리스트를 탭으로 분리하여 영어, 스페인 문장을 나눔\n",
        "\n",
        "  inp = [inp for targ, inp in pairs]\n",
        "  targ = [targ for targ, inp in pairs]\n",
        "\n",
        "  return targ, inp"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwQ5dudfv-nE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "271f6616-cec0-46ab-f67f-1c4f9bfc0c72"
      },
      "source": [
        "# 데이터 로드 및 샘플 프린트\n",
        "targ, inp = load_data(path_to_file)\n",
        "print(\"스페인어\")\n",
        "print(inp[-1])\n",
        "print(\"영어\")\n",
        "print(targ[-1])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "스페인어\n",
            "Si quieres sonar como un hablante nativo, debes estar dispuesto a practicar diciendo la misma frase una y otra vez de la misma manera en que un músico de banjo practica el mismo fraseo una y otra vez hasta que lo puedan tocar correctamente y en el tiempo esperado.\n",
            "영어\n",
            "If you want to sound like a native speaker, you must be willing to practice saying the same sentence over and over in the same way that banjo players practice the same phrase over and over until they can play it correctly and at the desired tempo.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gm5_hSzux2Mf"
      },
      "source": [
        "### 데이터셋 생성\n",
        "\n",
        "`tf.data.Dataset` 을 활용하여 데이터셋을 생성합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6H5vHIfbv-pk"
      },
      "source": [
        "BUFFER_SIZE = len(inp)\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# tf.data.Dataset.from_tensor_slices는 알아서 slice를 한다. -> 배치를 위한 전처리\n",
        "dataset = tf.data.Dataset.from_tensor_slices((inp, targ)).shuffle(BUFFER_SIZE) # shuffle로 랜덤하게 넣는다\n",
        "# 를 배치에 적용\n",
        "dataset = dataset.batch(BATCH_SIZE)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HaFvSOLEv-sw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5812361-7029-4f05-c8d6-9151f5ef4af7"
      },
      "source": [
        "# 배치 적용 샘플 테스트\n",
        "for example_input_batch, example_target_batch in dataset.take(1):\n",
        "  print(example_input_batch[:5])\n",
        "  print()\n",
        "  print(example_target_batch[:5])\n",
        "  break"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[b'\\xc2\\xbfEn qu\\xc3\\xa9 camino queda la playa?'\n",
            " b'Es un poco m\\xc3\\xa1s tarde de las once menos cuarto.'\n",
            " b'\\xc3\\x89l puede leer lo suficiente.'\n",
            " b'Tom tiene una hermana en Boston.' b'Nos subimos al bus en Shinjuku.'], shape=(5,), dtype=string)\n",
            "\n",
            "tf.Tensor(\n",
            "[b'Which way is the beach?' b'It is a little after a quarter to eleven.'\n",
            " b'He can read well.' b'Tom has a sister in Boston.'\n",
            " b'We got on the bus at Shinjuku.'], shape=(5,), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QemYBEMzgd6"
      },
      "source": [
        "### 텍스트 전처리\n",
        "\n",
        "이번 튜토리얼에서는 `tf.saved_model`을 활용하여 모델을 저장하는 것을 목표로 하고 있습니다.\n",
        "\n",
        "우선 표준화 작업부터 진행합니다.\n",
        "\n",
        "#### 표준화\n",
        "\n",
        "악센트를 분할하고, 호환성 문자를 해당 ASCII 문자로 대체하겠습니다.<br>\n",
        "`tensorflow_text` 패키지에 해당 작업들이 존재합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cOnrG8e0dJq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c98fd74d-9ec2-408e-86a9-0301bdf6ebb5"
      },
      "source": [
        "# 전처리 샘플\n",
        "example_text = tf.constant('¿Todavía está en casa?')\n",
        "\n",
        "print(example_text.numpy())\n",
        "print(tf_text.normalize_utf8(example_text, 'NFKD').numpy())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'\\xc2\\xbfTodav\\xc3\\xada est\\xc3\\xa1 en casa?'\n",
            "b'\\xc2\\xbfTodavi\\xcc\\x81a esta\\xcc\\x81 en casa?'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hunoT3Hg0dRT"
      },
      "source": [
        "# Standardization Function\n",
        "def tf_lower_and_split_punct(text):\n",
        "  # Split accecented characters.\n",
        "  text = tf_text.normalize_utf8(text, 'NFKD')\n",
        "  text = tf.strings.lower(text)\n",
        "  # Keep space, a to z, and select punctuation.\n",
        "  text = tf.strings.regex_replace(text, '[^ a-z.?!,¿]', '')\n",
        "  # Add spaces around punctuation.\n",
        "  text = tf.strings.regex_replace(text, '[.?!,¿]', r' \\0 ')\n",
        "  # Strip whitespace.\n",
        "  text = tf.strings.strip(text)\n",
        "\n",
        "  text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\n",
        "  return text"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LdUFg8z0dTo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f518983a-d586-4154-97ea-2c20d3fa54e8"
      },
      "source": [
        "print(example_text.numpy().decode())\n",
        "print(tf_lower_and_split_punct(example_text).numpy().decode())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "¿Todavía está en casa?\n",
            "[START] ¿ todavia esta en casa ? [END]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCLdhVw2Gobj"
      },
      "source": [
        "#### 텍스트 벡터화\n",
        "\n",
        "위의 Standardization Function 함수는 `tf.keras.layers.TextVectorization` 안에서 텍스트를 벡터화합니다.\n",
        "\n",
        "`tf.keras.layers.TextVectorization`는 어휘 추출 및 입력 텍스트를 토큰 시퀀스로 변환하는 레이어입니다.\n",
        "\n",
        "TextVectorization 층 또는 다른 전처리 층들은 `adapt` 메서드을 가지고 있습니다.\n",
        "이 메서드는 우선 트레이닝 데이터의 한 에포크를 읽은 후, `Model.fix`와 같이 작업을 수행합니다.\n",
        "이 `adapt` 메서드는 데이터에 기반하여 레이어를 초기화합니다. 여기에서 어휘를 결정합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ok2okn-p0dYe"
      },
      "source": [
        "max_vocab_size = 5000\n",
        "\n",
        "input_text_processor = tf.keras.layers.TextVectorization(\n",
        "    standardize=tf_lower_and_split_punct,\n",
        "    max_tokens=max_vocab_size)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhE8YbZP0dap"
      },
      "source": [
        "input_text_processor.adapt(inp)\n",
        "\n",
        "# Here are the first 10 words from the vocabulary:\n",
        "input_text_processor.get_vocabulary()[:10]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VbVi6UbJuAp"
      },
      "source": [
        "스페인어 TextVectorization 레이어가 영어로 build, .adapt()되는 예시"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePaKZ9yAJptd"
      },
      "source": [
        "output_text_processor = tf.keras.layers.TextVectorization(\n",
        "    standardize=tf_lower_and_split_punct,\n",
        "    max_tokens=max_vocab_size)\n",
        "\n",
        "output_text_processor.adapt(targ)\n",
        "output_text_processor.get_vocabulary()[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdzwtH6QWcJH"
      },
      "source": [
        "이제 레이어는 string 배치에서 token ID 배치로 변환할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGLyuHUWJpv3"
      },
      "source": [
        "example_tokens = input_text_processor(example_input_batch)\n",
        "example_tokens[:3, :10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VozlrBUYdi1"
      },
      "source": [
        "참고로 `get_vocabulary` 메서드는  token ID를 다시 text로 변환할 수 있는 메서드입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-ptkkz-JpyC"
      },
      "source": [
        "input_vocab = np.array(input_text_processor.get_vocabulary())\n",
        "tokens = input_vocab[example_tokens[0].numpy()]\n",
        "' '.join(tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5n66ZKH7ZePk"
      },
      "source": [
        "변환된 token ID들은 0으로 변환이 되어 있어서 쉽게 마스킹할 수 있습니다. 다음은 마스킹을 한 시각화 예입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GzuKZnWyJp0H"
      },
      "source": [
        "plt.subplot(1, 2, 1)\n",
        "plt.pcolormesh(example_tokens)\n",
        "plt.title('Token IDs')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.pcolormesh(example_tokens != 0)\n",
        "plt.title('Mask')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwhR8oU2qXYV"
      },
      "source": [
        "## 인코더, 디코더 모델\n",
        "\n",
        "하단의 그림은 모델의 overview를 나타냅니다. 각 타임스탭마다 디코더의 output은 인코딩된 input의 가중치 합과 결합하고, 다음 단어를 예측합니다.\n",
        "\n",
        "![encoder-decoder overview](https://www.tensorflow.org/images/seq2seq/attention_mechanism.jpg)\n",
        "\n",
        "우선 몇 가지 파라미터를 설정해두고 시작하도록 하겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCSkv1Q0Jp2P"
      },
      "source": [
        "embedding_dim = 256\n",
        "units = 1024"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Y0qugWnPKZ5"
      },
      "source": [
        "### 인코더\n",
        "\n",
        "위의 그림에서 파란색 부분을 인코더라고 합니다. \n",
        "\n",
        "인코더는 다음과 같이 동작합니다.\n",
        "\n",
        "1. token ID를 가져옵니다.(`input_text_processor`를 통해)\n",
        "2. 각 토큰에 대한 임베딩 벡터를 찾습니다.(`layers.Embedding`을 사용)\n",
        "3. 임베딩 벡터를 새로운 시퀀스로 처리합니다.(`layers.GRU`을 사용)\n",
        "\n",
        "이에 대한 리턴 값은 다음 두 개가 됩니다.\n",
        "1. 처리된 시퀀스 : 어텐션의 input으로 사용됩니다.\n",
        "2. internal state(내부 상태) : 디코더를 초기화하는데 사용됩니다. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ftfj9SMxJp4T"
      },
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, input_vocab_size, embedding_dim, enc_units):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.enc_units = enc_units\n",
        "    self.input_vocab_size = input_vocab_size\n",
        "\n",
        "    # The embedding layer converts tokens to vectors\n",
        "    # 임베딩을 수행하는 레이어(문자 데이터를 모델링을 위해 벡터로 임베딩)\n",
        "    self.embedding = tf.keras.layers.Embedding(self.input_vocab_size,\n",
        "                                               embedding_dim)\n",
        "\n",
        "    # The GRU RNN layer processes those vectors sequentially.\n",
        "    self.gru = tf.keras.layers.GRU(self.enc_units,\n",
        "                                   # Return the sequence and state\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "  def call(self, tokens, state=None):\n",
        "    shape_checker = ShapeChecker() # 위에 정의해 둔 ShapeChecker Class를 사용해 shape를 확인한다.\n",
        "    shape_checker(tokens, ('batch', 's'))\n",
        "\n",
        "    # 2. The embedding layer looks up the embedding for each token.\n",
        "    vectors = self.embedding(tokens)\n",
        "    shape_checker(vectors, ('batch', 's', 'embed_dim'))\n",
        "\n",
        "    # 3. The GRU processes the embedding sequence.\n",
        "    #    output shape: (batch, s, enc_units)\n",
        "    #    state shape: (batch, enc_units)\n",
        "    output, state = self.gru(vectors, initial_state=state)\n",
        "    shape_checker(output, ('batch', 's', 'enc_units'))\n",
        "    shape_checker(state, ('batch', 'enc_units'))\n",
        "\n",
        "    # 4. Returns the new sequence and its state.\n",
        "    # GRU를 통해 최종 output과, 디코더를 초기화할 state를 return합니다.\n",
        "    return output, state"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3l9mmdsyynF"
      },
      "source": [
        "# Convert the input text to tokens.\n",
        "example_tokens = input_text_processor(example_input_batch)\n",
        "\n",
        "# Encode the input sequence.\n",
        "encoder = Encoder(input_text_processor.vocabulary_size(),\n",
        "                  embedding_dim, units)\n",
        "example_enc_output, example_enc_state = encoder(example_tokens)\n",
        "\n",
        "print(f'Input batch, shape (batch): {example_input_batch.shape}')\n",
        "print(f'Input batch tokens, shape (batch, s): {example_tokens.shape}')\n",
        "print(f'Encoder output, shape (batch, s, units): {example_enc_output.shape}')\n",
        "print(f'Encoder state, shape (batch, units): {example_enc_state.shape}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0brLDMmgbq9"
      },
      "source": [
        "인코더는 위의 주석에 달려있듯이 디코더를 초기화할 state를 return합니다.  \n",
        "이것은 RNN이 여러 호출을 통해 시퀀스를 처리할 수 있도록 상태를 반환하는 방법처럼 일반적인 방법으로,\n",
        "앞으로 실습에서 더 많은 디코더 빌드 방법을 확인할 수 있을 것입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_RVESWP1fAs"
      },
      "source": [
        "### 어텐션(Attention)\n",
        "\n",
        "**참고 : 원문에서는 attention head라고 표현하고 있습니다.**\n",
        "\n",
        "디코더는 어텐션을 사용하여 입력 시퀀스의 일부에 선택적으로 포커싱합니다.  \n",
        "어텐션은 각 예제에 대한 입력으로 벡터 시퀀스를 사용하고, 각 예제에 대해 어텐션 벡터를 반환합니다.  \n",
        "이 어텐션 레이어는 `layers.GlobalAveragePoling1D`와 유사하지만, GAP와는 달리 가중 평균을 수행합니다.\n",
        "\n",
        "이제 어텐션이 어떻게 동작하는지 살펴보도록 하겠습니다.\n",
        "\n",
        "![ATTENTION_1](https://www.tensorflow.org/text/tutorials/images/attention_equation_1.jpg)\n",
        "![ATTENTION_2](https://www.tensorflow.org/text/tutorials/images/attention_equation_2.jpg)\n",
        "\n",
        "각각의 기호는 다음의 뜻과 같습니다.\n",
        "\n",
        "* $s$ : 인코더 인덱스\n",
        "* $t$ : 디코더 인덱스\n",
        "* $\\alpha_{ts}$ : 어텐션 가중치\n",
        "* $h_s$ : 인코더의 아웃풋 (the attention \"key\" and \"value\" in transformer terminology).\n",
        "* $h_t$ : 디코더의 상태 (the attention \"query\" in transformer terminology).\n",
        "* $c_t$ : 결과값(컨텍스트 벡터)\n",
        "* $a_t$ : 컨텍스트와 쿼리를 결합한 최종 값\n",
        "\n",
        "방정식에 대해서 설명하면,\n",
        "\n",
        "1. 어텐션 가중치($\\alpha_{ts}$)를 계산하는 식입니다. 이 가중치는 인코더의 아웃풋 시퀀스들을 소프트맥스 결합하여 나온 값입니다.  \n",
        "    **설명 추가 : 이 연산을 통해 나온 가중치로 어떠한 $_s$에 집중할 지를 결정합니다.**\n",
        "2. 어텐션 가중치와 인코더의 아웃풋을 가중합해 컨텍스트 벡터를 계산합니다.  \n",
        "    **설명 추가 : 매 디코더 연산 step마다 가중치가 바뀌어야 하므로 반복 수행합니다.**\n",
        "\n",
        "마지막으로 $score$ 함수를 알아보겠습니다. 이 함수는 키-쿼리 쌍에 대한 스칼라 로짓 점수를 계산합니다.\n",
        "두 가지 계산 방법이 존재하는데,\n",
        "\n",
        "![ATTENTION_3](https://www.tensorflow.org/text/tutorials/images/attention_equation_4.jpg)\n",
        "\n",
        "이번 튜토리얼에서는 [Bahdanau's additive attention](https://arxiv.org/pdf/1409.0473.pdf)를 사용하도록 하겠습니다. 텐서플로우에서는 `layers.Attention` 와\n",
        "`layers.AdditiveAttention` 모두 구현이 되어 있다고 합니다.  \n",
        "이 클래스는 'layers.Dense' 레이어 쌍에서 가중치 행렬을 처리하고 내장 구현을 호출합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUS_p2khyyop"
      },
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super().__init__()\n",
        "    # For Eqn. (4), the  Bahdanau attention\n",
        "    self.W1 = tf.keras.layers.Dense(units, use_bias=False)\n",
        "    self.W2 = tf.keras.layers.Dense(units, use_bias=False)\n",
        "\n",
        "    self.attention = tf.keras.layers.AdditiveAttention()\n",
        "\n",
        "  def call(self, query, value, mask):\n",
        "    shape_checker = ShapeChecker()\n",
        "    shape_checker(query, ('batch', 't', 'query_units'))\n",
        "    shape_checker(value, ('batch', 's', 'value_units'))\n",
        "    shape_checker(mask, ('batch', 's'))\n",
        "\n",
        "    # From Eqn. (4), `W1@ht`.\n",
        "    w1_query = self.W1(query)\n",
        "    shape_checker(w1_query, ('batch', 't', 'attn_units'))\n",
        "\n",
        "    # From Eqn. (4), `W2@hs`.\n",
        "    w2_key = self.W2(value)\n",
        "    shape_checker(w2_key, ('batch', 's', 'attn_units'))\n",
        "\n",
        "    query_mask = tf.ones(tf.shape(query)[:-1], dtype=bool)\n",
        "    value_mask = mask\n",
        "\n",
        "    context_vector, attention_weights = self.attention(\n",
        "        inputs = [w1_query, value, w2_key],\n",
        "        mask=[query_mask, value_mask],\n",
        "        return_attention_scores = True,\n",
        "    )\n",
        "    shape_checker(context_vector, ('batch', 't', 'value_units'))\n",
        "    shape_checker(attention_weights, ('batch', 't', 's'))\n",
        "\n",
        "    return context_vector, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewnvpJRfgPBh"
      },
      "source": [
        "### 어텐션 레이어 테스트\n",
        "우선 `BahdanauAttention` 레이어를 생성합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v50JRUJXyyrl"
      },
      "source": [
        "attention_layer = BahdanauAttention(units)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_aZ3WyOqgjIi"
      },
      "source": [
        "이 어텐션 레이어는 3개의 인풋을 필요합니다.\n",
        "\n",
        "`query` : 디코더에 의해 생성되는 값  \n",
        "`value` : 인코더의 아웃풋값.  \n",
        "`mask` : 패딩을 제거하고자 한다면 다음과 같이 사용한다. `example_tokens != 0`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QAx2havyyuU"
      },
      "source": [
        "(example_tokens != 0).shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGrV3CmRiwox"
      },
      "source": [
        "The vectorized implementation of the attention layer lets you pass a batch of sequences of query vectors and a batch of sequence of value vectors. The result is:\n",
        "\n",
        "A batch of sequences of result vectors the size of the queries.\n",
        "A batch attention maps, with size (query_length, value_length)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cC6FvpQtyy2G"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWiGpWq7yy4X"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHEAQ-pTyy7C"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4-kPt9Fyy9Y"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LanRyIoQyy_k"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kL2BDsbnyzBq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}